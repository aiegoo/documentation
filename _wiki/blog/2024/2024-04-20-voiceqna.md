---
layout: post
title: "AWS Korean Voice ChatGPT: Enhancing Conversational AI with Hugging Face"
name: "voiceqna"
tags: [nlp ai gpt]
tagName: nlp
permalink: 2024-04-20-voiceqna.html
sidebar: other_sidebar
folder: blog
collection: wiki
categories: wiki
keywords: "chatgpt, nlp, korean, voice to text, text to voice, huggingface, Korean language model, deep learning, virtual assistant"
summary: "Sat, Apr 20, 24, Leveraging state-of-the-art deep learning techniques and pretrained language models, Korean Voice ChatGPT enables seamless and natural conversations in Korean, catering to diverse applications ranging from customer service chatbots to virtual assistants. With Hugging Face's robust infrastructure and expertise in NLP, Korean Voice ChatGPT promises to revolutionize Korean-language conversational AI experiences."
excerpt_separator: <!--more-->
toc: true
public: true
parent: [[Wiki-Setting-Category]] 
date: 2024-04-20T22:52:12 +0900
updated: 2024-04-20 22:52
---
* TOC
{:toc}

{{site.data.alerts.callout_warning}}This is a draft, the content is not complete and of poor quality!{{site.data.alerts.end}}
## repository
[koreanQ&A](https://github.com/aiegoo/korean-voice-qna.git) latest on moha branch

<style>
#customtable {
  font-size: 0.6rem;
}
.customtable tr:nth-child(odd) { background-color: #0087ff6e; }
.customtable td:nth-child(2) { color: white; background: #0087ff6e; }
.customtable tr:nth-child(3) { color: black; background: yellow; }
.customtable td:nth-child(even) { color: black; background: #b1b0e1}
</style>

{:#high-perfromance-table}

{:.customtable}
|---
| HIGH PERFORMANCE PROCESSING        | SUPPORT FOR VIRTUAL WORKSTATIONS & VIRTUAL DESKTOP APPLICATIONS | HIGH PERFORMANCE NETWORKING & STORAGE          |
|------------------------------------|------------------------------------------------------------------|------------------------------------------------|
| G3 instances feature up to 64 vCPUs based on custom 2.7 GHz Intel Xeon E5 2686 v4 processors and 488 GiB of DRAM host memory. Backed by up to 4 NVIDIA Tesla M60 GPUs, with each GPU delivering up to 2,048 parallel processing cores and 8 GiB of GPU memory, G3 instances can enable demanding graphics applications like seismic visualization, computer-aided design, medical image processing, and virtual reality experiences in the cloud. G3 instances also feature a hardware encoder supporting up to 10 H.265 (HEVC) 1080p30 streams and up to 18 H.264 1080p30 streams. | G3 instances support OpenGL 4.5, DirectX 12.0, CUDA 8.0, and OpenCL 1.2. They are the first Amazon EC2 instances to support NVIDIA GRID Virtual Workstation capabilities with streaming support for four monitors each with up to 4K resolution (4096 x 2160 pixels). G3 instances also support GRID Virtual Application capabilities for virtual desktop applications and virtualization software, such as Citrix XenApp Essentials and VMware Horizon, enabling up to 25 concurrent users per GPU. | Next generation Elastic Network Adapter (ENA) technology provides G3 instances with high throughput, low latency interfaces for networking and Amazon Elastic Block Store (Amazon EBS). G3 instances offer up to 20 Gbps of network bandwidth and up to 14 Gbps of dedicated bandwidth to EBS. |


<table id="high-performance-table" class="customtable">
<thead>
<tr>
<th>HIGH PERFORMANCE PROCESSING</th>
<th>SUPPORT FOR VIRTUAL WORKSTATIONS & VIRTUAL DESKTOP APPLICATIONS</th>
<th>HIGH PERFORMANCE NETWORKING & STORAGE</th>
</tr>
</thead>
<tbody>
<tr>
<td>G3 instances feature up to 64 vCPUs based on custom 2.7 GHz Intel Xeon E5 2686 v4 processors and 488 GiB of DRAM host memory. Backed by up to 4 NVIDIA Tesla M60 GPUs, with each GPU delivering up to 2,048 parallel processing cores and 8 GiB of GPU memory, G3 instances can enable demanding graphics applications like seismic visualization, computer-aided design, medical image processing, and virtual reality experiences in the cloud. G3 instances also feature a hardware encoder supporting up to 10 H.265 (HEVC) 1080p30 streams and up to 18 H.264 1080p30 streams.</td>
<td>G3 instances support OpenGL 4.5, DirectX 12.0, CUDA 8.0, and OpenCL 1.2. They are the first Amazon EC2 instances to support NVIDIA GRID Virtual Workstation capabilities with streaming support for four monitors each with up to 4K resolution (4096 x 2160 pixels). G3 instances also support GRID Virtual Application capabilities for virtual desktop applications and virtualization software, such as Citrix XenApp Essentials and VMware Horizon, enabling up to 25 concurrent users per GPU.</td>
<td>Next generation Elastic Network Adapter (ENA) technology provides G3 instances with high throughput, low latency interfaces for networking and Amazon Elastic Block Store (Amazon EBS). G3 instances offer up to 20 Gbps of network bandwidth and up to 14 Gbps of dedicated bandwidth to EBS.</td>
</tr>
</tbody>
</table>

## history

{{site.data.alerts.details}}
```bash
history
    1  sudo apt update
    2  sudo apt install apt-transport-https ca-certificates curl software-properties-common
    3  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
    4  sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu focal stable"
    5  apt-cache policy docker-ce
    6  sudo apt install docker-ce
    7  sudo systemctl status docker
    8  docker login registry.digitalocean.com
    9  sudo docker login registry.digitalocean.com
   10  docker pull registry.digitalocean.com/genta-inference-registry/korean-chatbot:latest
   11  sudo docker pull registry.digitalocean.com/genta-inference-registry/korean-chatbot:latest
   12  docker network create mongo-network
   13  sudo docker network create mongo-network
   14  sudo docker run -d --network mongo-network --name mongodb -p 27017:27017 -d mongo
   15  git clone https://github.com/aiegoo/Korean-Voice-QnA
   16  python3
   17  cd Korean-Voice-QnA/
   18  dir
   19  pip install -r requirements-min.txt
   20  pip3 install -r requirements-min.txt
   21  sudo apt install python3-pip
   22  pip3 install -r requirements-min.txt
   23  ct2-transformers-converter --model openai/whisper-large-v2 --output_dir model --copy_files tokenizer.json --quantization float8
   24  pip install faster-whisper
   25  ct2-transformers-converter --model openai/whisper-large-v2 --output_dir model --copy_files tokenizer.json --quantization float8
   26  pip install transformers[torch]>=4.23
   27  ct2-transformers-converter --model openai/whisper-large-v2 --output_dir whisper-large-v2-ct2     --quantization float8
   28  python3 -m ct2-transformers-converter --model openai/whisper-large-v2 --output_dir whisper-large-v2-ct2     --quantization float8
   29  docker images
   30  sudo docker images
   31  dockerdocker ps
   32  sudo docker ps
   33  docker run -it --rm --name api-container -p 5000:5000 --network mongo-network registry.digitalocean.com/genta-inference-registry/korean-chatbot
   34  sudo docker run -it --rm --name api-container -p 5000:5000 --network mongo-network registry.digitalocean.com/genta-inference-registry/korean-chatbot
   35  cd ..
   36  rm -r Korean-Voice-QnA/
   37  rm -r Korean-Voice-QnA/ -y
   38  rm -r Korean-Voice-QnA/
   39  y
   40  history
   41  docker images
   42  sudo docker images
   43  sudo docker rm     1  sudo apt update
   44  clear
   45  sudo docker images
   46  sudo docker rm registry.digitalocean.com/genta-inference-registry/korean-chatbot
   47  sudo docker rmi registry.digitalocean.com/genta-inference-registry/korean-chatbot
   48  sudo docker images
   49  sudo docker ps
   50  sudo docker pull registry.digitalocean.com/genta-inference-registry/uconcreative-cpu:latest
   51  docker login registry.digitalocean.com
   52  sudo docker login registry.digitalocean.com
   53  sudo docker pull registry.digitalocean.com/genta-inference-registry/uconcreative-cpu:latest
   54  sudo docker run -it --rm --name api-container -p 5000:5000 --network mongo-network registry.digitalocean.com/genta-inference-registry/uconcreative-cpu:latest
   55  sudo docker images
   56  df -h
   57  dir
   58  sudo docker login registry.digitalocean.com
   59  sudo docker ps
   60  sudo docker network create mongo-network
   61  sudo docker run -d --network mongo-network --name mongodb -p 27017:27017 -d mongo
   62  sudo docker ps
   63  sudo docker ps -a
   64  sudo docker rm 1d6d
   65  sudo docker ps
   66  sudo docker run -d --network mongo-network --name mongodb -p 27017:27017 -d mongo
   67  sudo docker run -it --rm -d --name api-container -p 5000:5000 --network mongo-network registry.digitalocean.com/genta-inference-registry/uconcreative-cpu:latest
   68  sudo docker ps
   69  sudo docker logs e909b
   70  sudo docker ps
   71  exit
   72  vim .ssh/authorized_keys 
   73  ifconfig
   74  ip -a
   75  ip
   76  ifconfig
   77  sudo apt install net-tools
   78  ifconfig
   79  sudo su
   80  dir
   81  sudo docker ps
   82  git clone https://huggingface.co/spaces/aiegoo/whisper-chatbot-ko
   83  cd whisper-chatbot-ko/
   84  dir
   85  cd ..
   86  rm -r whisper-chatbot-ko/
   87  dir
   88  rm -r whisper-chatbot-ko/
   89  y
   90  dir
   91  rm -r whisper-chatbot-ko/
   92  dir
   93  clear
   94  git clone https://github.com/aiegoo/Korean-Voice-QnA
   95  git clone https://github.com/aiegoo/Korean-Voice-QnA.git
   96  sudo git clone https://github.com/aiegoo/Korean-Voice-QnA.git
   97  git clone git clone https://github.com/rifkybujana/Korean-Voice-QnA
   98  git clone https://github.com/rifkybujana/Korean-Voice-QnA
   99  git.exe clone https://github.com/rifkybujana/Korean-Voice-QnA
  100  exit
  101  screen -list
  102  ufw allow 7860
  103  sudo ufw allow 7860
  104  python app_chat_demo.py 
  105  python3 app_chat_demo.py 
  106  python3 -m venv venv
  107  sudo apt install python3.8-venv
  108  python3 -m venv venv
  109  dir
  110  source venv/bin/activate
  111  pip install -r requirements-min.txt 
  112  exit
  113  git
  114  git clone https://github.com/aiegoo/Korean-Voice-QnA.git
  115  cd Korean-Voice-QnA/
  116  dir
  117  vim app_chat_demo.py 
  118  clear
  119  screen
  120  clear
  121  screen -list
  122  rm -r venv/
  123  dir
  124  cat requirements-min.txt 
  125  pip install numpy miniaudio==1.55 gTTS python-dotenv gradio librosa soundfile jiwer accelerate evaluate
  126  pip install fsspec[http]==2023.1.0
  127  pip install numpy miniaudio==1.55 gTTS python-dotenv gradio librosa soundfile jiwer accelerate evaluate
  128  screen
  129  screen -list
  130  python app_chat_demo.py 
  131  python3 app_chat_demo.py 
  132  docker ps
  133  sudo docker ps
  134  sudo docker ps -a
  135  sudo docker run -it --rm -d --name api-container -p 5000:5000 --network mongo-network registry.digitalocean.com/genta-inference-registry/uconcreative-cpu:latest
  136  python3 app_chat_demo.py 
  137  cd ..
  138  rm -r Korean-Voice-QnA/
  139  y
  140  clear
  141  exit
  142  sudo docker ps
  143  screen -list
  144  screen -r 53451
  145  exit
  146  sudo docker ps
  147  sudo docker stop f3618
  148  sudo docker ps
  149  sudo docker run -it --rm -d --name api -p 5000:5000 --network mongo-network registry.digitalocean.com/genta-inference-registry/uconcreative-cpu:latest
  150  sudo docker run -it --rm -d --name demo -p 7860:7860 --network mongo-network registry.digitalocean.com/genta-inference-registry/uconcreative-demo:latest
  151  docker ps
  152  sudo docker ps
  153  sudo docker logs 5867
  154  exit
  155  sudo docker ps
  156  sudo docker stop 5867a06e73b8 4cc04f088db7
  157  sudo docker images
  158  sudo docker rmi 675e0aadd821 a3ddf665f344
  159  sudo docker run -it --rm -d --name api -p 5000:5000 --network mongo-network registry.digitalocean.com/genta-inference-registry/uconcreative-cpu:latest
  160  sudo docker run -it --rm -d --name demo -p 80:80 --network mongo-network registry.digitalocean.com/genta-inference-registry/uconcreative-demo:latest
  161  history
  162  clear
  163  ipconfig
  164  ifconfig 
  165  sudo su
  166  ifconfig -a
  167  sudo su
  168  cat ~/.ssh/authorized_keys 
  169  clear
  170  exit
  171  su -
  172  exit
  173  sudo docker ps
  174  sudo docker stop b61c
  175  sudo docker images
  176  sudo docker rmi 73cc263256c5 889c0a223f53
  177  sudo docker run -it --rm -d --name api -p 5000:5000 --network mongo-network registry.digitalocean.com/genta-inference-registry/uconcreative-cpu:latest
  178  sudo docker ps
  179  sudo docker ps -a
  180  sudo docker run -it --rm -d --name api -p 5000:5000 --network mongo-network registry.digitalocean.com/genta-inference-registry/uconcreative-cpu:latest
  181  sudo docker ps
  182  exit
  183  sudo docker ps
  184  sudo docker run -it --rm -d --name api -p 5000:5000 --network mongo-network registry.digitalocean.com/genta-inference-registry/uconcreative-cpu:latest
  185  sudo docker ps
  186  sudo docker images
  187  sudo docker rmi ca9fcffbae25
  188  sudo docker run -it --rm -d --name api -p 5000:5000 --network mongo-network registry.digitalocean.com/genta-inference-registry/uconcreative-cpu:latest
  189  sudo docker ps
  190  docker network create mongo-network
  191  sudo docker network create mongo-network
  192  sudo docker run -d --network mongo-network --name mongodb -p 27017:27017 -d mongo
  193  sudo docker ps
  194  sudo docker ps -a
  195  sudo docker rm 08a74ca5698e
  196  sudo docker run -d --network mongo-network --name mongodb -p 27017:27017 -d mongo
  197  sudo docker run -it --rm -d --name api -p 5000:5000 --network mongo-network registry.digitalocean.com/genta-inference-registry/uconcreative-cpu:latest
  198  sudo docker ps
  199  sudo docker logs 79eada37d5d5
  200  sudo docker run -it --rm -d --name demo -p 80:80 --network mongo-network registry.digitalocean.com/genta-inference-registry/uconcreative-demo:latest
  201  ls
  202  cat ~/.ssh/authorized_keys 
  203  sudo su
  204  sudo vim /etc/ssh/sshd_conf
  205  sudo vim /etc/ssh/sshd_config
  206  sudo system sshd restart
  207  sudo service sshd restart 
  208  ll
  209  clear
  210  sudo su
  211  logout
  212  sudo su
  213  w
  214  history
  215  cat history >> Jan202024.txt
  216  echo history >> Jan202024.txt
  217  pwd
  218  history >> Jan202024.txt

```
{{site.data.alerts.ended}}

### AWS spec

| Name        | GPUs | vCPU | Memory (GiB) | GPU Memory (GiB) | Price/hr* (Linux) | Price/hr* (Windows) | 1-yr Reserved Instance Effective Hourly* (Linux) | 3-yr Reserved Instance Effective Hourly* (Linux) |
|-------------|------|------|--------------|-------------------|-------------------|---------------------|-------------------------------------------------|-------------------------------------------------|
| g3s.xlarge | 1    | 4    | 100         | 8                 | $0.75             | $0.93               | $0.525                                          | $0.405                                          |

![image](/images/ai/aws_voiceqna_setup.png)


{% include taglogic.html %}

{% include links.html %}

{% include commento.html %}

{{site.data.alerts.hr_shaded}}
